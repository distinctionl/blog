<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: notes | The Distinctionl Blog]]></title>
  <link href="http://blog.distinctionl.com/blog/categories/notes/atom.xml" rel="self"/>
  <link href="http://blog.distinctionl.com/"/>
  <updated>2015-01-13T10:19:52+00:00</updated>
  <id>http://blog.distinctionl.com/</id>
  <author>
    <name><![CDATA[Oliver Woodford]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ML fitting of complex distributions]]></title>
    <link href="http://blog.distinctionl.com/blog/2014/10/30/ml-fitting-of-complex-distributions/"/>
    <updated>2014-10-30T15:52:23+00:00</updated>
    <id>http://blog.distinctionl.com/blog/2014/10/30/ml-fitting-of-complex-distributions</id>
    <content type="html"><![CDATA[<p>This post gives me the chance to show off something I&#39;ve just added support for: LaTeX equations using MathJax. Beautiful!</p>

<p>Let&#39;s imagine that I have some training data, $\{\x_1,..,\x_N\}$, and a non-negative function, $f(\x;\params)$, parameterized by $\params$, that I want to use as a probability distribution to fit to the data. The probability distribution is therefore given by</p>

<p>$$
p(\x;\params) = \frac{f(\x;\params)}{\int f(\vect{y};\params)\d\vect{y}}.
$$</p>

<p>A common thing to do is to maximize the likelihood (ML learning, not to be confused with machine learning) of the data, w.r.t. $\params$, i.e.</p>

<p>$$
\params^* = \argmax_\params \left(\int f(\vect{y};\params)\d\vect{y}\right)^{-N}\prod_{i=1}^N f(\x_i;\params).
$$</p>

<p>Whilst $f(\x;\params)$ is computable (since we defined it), the integral $\int f(\vect{y};\params) \d\vect{y}$ may not not be. For example, this is the case with complex models such as those defined by many deep networks. This creates a problem in ML fitting of the distribution.</p>

<!-- more -->

<p>There are several ways of overcoming this problem, which I&#39;m not going to list (though I invite people to name methods in the comments), but I will mention one: <strong>Contrastive Divergence</strong>, introduced by Geoffrey Hinton in 2002 in his paper <em><a href="http://www.mitpressjournals.org/doi/abs/10.1162/089976602760128018">&quot;Training products of experts by minimizing contrastive divergence&quot;</a></em>. It describes a way of computing a gradient of the training data likelihood w.r.t. model parameters, without computing the normalized likelihood itself, by perturbing the training data in the direction of the current model using <a href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a> sampling.</p>

<p>I read and implemented this approach during my DPhil in 2005, but I thought the original paper on the subject was rather heavy going. So, because I&#39;m the kind of guy who likes to share knowledge, and to do so in an accessible way, I gave a couple of introductory seminars on the subject in Oxford.</p>

<p>Around the same time, January 2006, I also published some easy-to-follow <a href="https://sites.google.com/site/oliverwoodford/notes/NotesOnCD.pdf">notes on contrastive divergence</a> online. Since then, people seem to have found them useful. They&#39;ve been referenced in several other course notes, seminar slides and blogs. I&#39;ll even quote one: <em>&quot;For me, this paper is the best; precise, intuitive and make you hungry to know more!&quot;</em>, <a href="http://kittipatkampa.wordpress.com/2010/03/23/contrastive-divergence-for-parameter-estimation-in-dscrfs/">Kittipat Kampa</a>. So if you want to fit a non-integrable probability distribution to data, and are considering using contrastive divergence, give my notes a read.</p>
]]></content>
  </entry>
  
</feed>
